{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3. Факторизация матрицы (3 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "SMALL_DATA_PATH = 'file:///home/cloudera/Desktop/ml_data/ml_latest_small/ratings.csv'\n",
    "BIG_DATA_PATH = 'file:///home/cloudera/Desktop/ml_data/ml_latest_big/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test_data(data_path, parts, seed=123):\n",
    "    print(f'Use data path: \"{data_path}\"')\n",
    "    \n",
    "    ratings_df = sqlContext.read.load(\n",
    "        data_path,\n",
    "        format='com.databricks.spark.csv',\n",
    "        header='true',\n",
    "        inferSchema='true',\n",
    "        sep=','\n",
    "    )\n",
    "    ratings_df.persist()\n",
    "    ratings_df.show(5)\n",
    "\n",
    "    df_train, df_test = ratings_df.randomSplit(parts, seed=seed)\n",
    "    df_train.persist(), df_test.persist()\n",
    "    print(f'Train data count: {df_train.count()}. Test data count: {df_test.count()}\\n\\n')\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разделите данные с рейтингами на обучающее (train - 0.8) и тестовое подмножества (test - 0.2).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use data path: \"file:///home/cloudera/Desktop/ml_data/ml_latest_small/ratings.csv\"\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Train data count: 80838. Test data count: 19998\n",
      "\n",
      "\n",
      "Use data path: \"file:///home/cloudera/Desktop/ml_data/ml_latest_big/ratings.csv\"\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    307|   3.5|1256677221|\n",
      "|     1|    481|   3.5|1256677456|\n",
      "|     1|   1091|   1.5|1256677471|\n",
      "|     1|   1257|   4.5|1256677460|\n",
      "|     1|   1449|   4.5|1256677264|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Train data count: 22200602. Test data count: 5552842\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parts = (0.8, 0.2)\n",
    "\n",
    "small_df_train, small_df_test = get_train_and_test_data(SMALL_DATA_PATH, parts)\n",
    "big_df_train, big_df_test = get_train_and_test_data(BIG_DATA_PATH, parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oпределите среднее значение рейтинга в обучающем подмножестве.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rating in small data: 3.4985155496177542\n",
      "\n",
      "Mean rating in big data: 3.530478362703858\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "def get_mean_movie_rating(df_train):\n",
    "    return df_train.select(F.mean('rating').alias('avg')).collect()[0]['avg']\n",
    "\n",
    "\n",
    "small_mean_movie_rating = get_mean_movie_rating(small_df_train)\n",
    "print(f'Mean rating in small data: {small_mean_movie_rating}\\n')\n",
    "\n",
    "big_mean_movie_rating = get_mean_movie_rating(big_df_train)\n",
    "print(f'Mean rating in big data: {big_mean_movie_rating}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bычислите RMSE для тестового подмножества, если для всех значений из test предсказывается среднее значение рейтинга.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+------------------+\n",
      "|userId|movieId|rating|timestamp|        prediction|\n",
      "+------+-------+------+---------+------------------+\n",
      "|     1|      3|   4.0|964981247|3.4985155496177542|\n",
      "|     1|      6|   4.0|964982224|3.4985155496177542|\n",
      "|     1|     47|   5.0|964983815|3.4985155496177542|\n",
      "|     1|    151|   5.0|964984041|3.4985155496177542|\n",
      "|     1|    163|   5.0|964983650|3.4985155496177542|\n",
      "+------+-------+------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RMSE for small data: 1.0425819010275184\n",
      "\n",
      "+------+-------+------+----------+-----------------+\n",
      "|userId|movieId|rating| timestamp|       prediction|\n",
      "+------+-------+------+----------+-----------------+\n",
      "|     1|    481|   3.5|1256677456|3.530478362703858|\n",
      "|     1|   1091|   1.5|1256677471|3.530478362703858|\n",
      "|     1|   1257|   4.5|1256677460|3.530478362703858|\n",
      "|     1|   2478|   4.0|1256677239|3.530478362703858|\n",
      "|     1|   2986|   2.5|1256677496|3.530478362703858|\n",
      "+------+-------+------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RMSE for big data: 1.0666867487824185\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "rmse_evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
    "\n",
    "\n",
    "def fill_prediction_column(df_test, mean_movie_rating):\n",
    "    df_test_with_prediction = df_test.withColumn('prediction', F.lit(mean_movie_rating))\n",
    "    df_test_with_prediction.show(5)\n",
    "    return df_test_with_prediction\n",
    "\n",
    "\n",
    "small_df_test_with_prediction = fill_prediction_column(small_df_test, small_mean_movie_rating)\n",
    "print(f'RMSE for small data: {rmse_evaluator.evaluate(small_df_test_with_prediction)}\\n')\n",
    "\n",
    "big_df_test_with_prediction = fill_prediction_column(big_df_test, big_mean_movie_rating)\n",
    "print(f'RMSE for big data: {rmse_evaluator.evaluate(big_df_test_with_prediction)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выберите модель ALS по минимальному значению RMSE. Для этого используйте kfolds c k=4.**\n",
    "\n",
    "**Если какие-то элементы из тестового/валидационного подмножества не встречались в обучающем, то RMSE будет NaN.**\n",
    "\n",
    "**Поэтому заранее уберите из тестового/валидационного подмножества такие элементы.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Параметры\n",
    "ranks = (5, 10, 15)  # Kоличество факторов\n",
    "regParams = (0.001, 0.01, 0.1, 1, 10)  # Pегуляризация\n",
    "kfolds = 4\n",
    "\n",
    "als = ALS(\n",
    "    seed=123,\n",
    "    maxIter=10,\n",
    "    numUserBlocks=10,\n",
    "    numItemBlocks=10,\n",
    "    userCol='userId',\n",
    "    itemCol='movieId',\n",
    "    ratingCol='rating',\n",
    "    coldStartStrategy='drop',\n",
    ")\n",
    "paramsGrid = (\n",
    "    ParamGridBuilder()\n",
    "        .addGrid(als.rank, ranks)\n",
    "        .addGrid(als.regParam, regParams)\n",
    "        .build()\n",
    ")\n",
    "cross_validator = CrossValidator(estimator=als,\n",
    "                                 estimatorParamMaps=paramsGrid,\n",
    "                                 evaluator=rmse_evaluator,\n",
    "                                 numFolds=kfolds)\n",
    "\n",
    "def calculate_rmse_for_best_als_model(df_train, df_test):\n",
    "    cv_model = cross_validator.fit(df_train)\n",
    "    print(f'Best rank: {cv_model.bestModel.rank}')\n",
    "    # FIXME(a.telyshev): py4j.Py4JException: Method getRegParam([]) does not exist\n",
    "    # print(f'Best regularization: {cv_model.bestModel._java_obj.getRegParam()}')\n",
    "    \n",
    "    predictions = cv_model.transform(df_test)\n",
    "    predictions.show(5)\n",
    "    \n",
    "    return rmse_evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small data processing...\n",
      "Best rank: 10\n",
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|   133|    471|   4.0| 843491793| 2.9822454|\n",
      "|   599|    471|   2.5|1498518822| 2.6454818|\n",
      "|   603|    471|   4.0| 954482443| 2.7023568|\n",
      "|   217|    471|   2.0| 955943727| 3.4777524|\n",
      "|   136|    471|   4.0| 832450058| 3.9017246|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RMSE: 0.8838615498556199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Small data processing...')\n",
    "print(f'RMSE: {calculate_rmse_for_best_als_model(small_df_train, small_df_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big data processing...\n"
     ]
    }
   ],
   "source": [
    "print('Big data processing...')\n",
    "print(f'RMSE: {calculate_rmse_for_best_als_model(big_df_train, big_df_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
